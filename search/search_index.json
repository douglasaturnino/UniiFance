{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introdu\u00e7\u00e3o","text":"<p>Este \u00e9 um projeto fict\u00edcio. A empresa, o contexto e as perguntas de neg\u00f3cios n\u00e3o s\u00e3o reais.  Este portf\u00f3lio est\u00e1 seguindo as recomenda\u00e7\u00f5es do blog da Comunidade DS.</p> <p>O Banco UniFinance, uma institui\u00e7\u00e3o financeira l\u00edder e confi\u00e1vel, destaca-se no mercado pela sua dedica\u00e7\u00e3o em fornecer solu\u00e7\u00f5es de cr\u00e9dito acess\u00edveis e sob medida para empres\u00e1rios do setor comercial. Com foco em empr\u00e9stimos flex\u00edveis e acess\u00edveis, nossa equipe altamente qualificada trabalha em estreita colabora\u00e7\u00e3o com os clientes para atender \u00e0s suas necessidades financeiras espec\u00edficas.</p> <p>Atualmente o banco est\u00e1 passando por uma revis\u00e3o em como ele empresta o dinheiro para os seus clientes, assim o objetivo \u00e9 criar processos inteligentes para a previs\u00e3o de que algu\u00e9m pode vim a passar por dificuldades financeiras nos pr\u00f3ximos dois anos.</p>"},{"location":"#entendimento-do-negocio","title":"Entendimento do neg\u00f3cio","text":"<p>No Banco UniFinance, quando um cliente solicita um empr\u00e9stimo, iniciamos um processo de avalia\u00e7\u00e3o que inclui a an\u00e1lise de diversos fatores, um dos quais \u00e9 a poss\u00edvel ocorr\u00eancia de dificuldades financeiras nos pr\u00f3ximos dois anos. Isso \u00e9 crucial para identificar e mitigar riscos que poderiam levar \u00e0 inadimpl\u00eancia, o que, por sua vez, afetaria negativamente o banco. Nossa prioridade \u00e9 garantir empr\u00e9stimos respons\u00e1veis e sustent\u00e1veis, tanto para o benef\u00edcio do cliente quanto para a seguran\u00e7a financeira da institui\u00e7\u00e3o.</p>"},{"location":"#premissas-de-negocio","title":"Premissas de neg\u00f3cio","text":"<ul> <li>Todos os produtos de dados entregues devem ser acess\u00edveis via internet.</li> </ul> <p>As vari\u00e1veis do dataset original s\u00e3o:</p> Nome da vari\u00e1vel Descri\u00e7\u00e3o target Pessoa sofreu inadimpl\u00eancia de 90 dias TaxaDeUtilizacaoDeLinhasNaoGarantidas Saldo total em cart\u00f5es de cr\u00e9dito e linhas de cr\u00e9dito pessoais, exceto im\u00f3veis e sem Idade Idade do cliente em anos NumeroDeVezes30-59DiasAtrasoNaoPior N\u00famero de vezes que o mutu\u00e1rio apresentou atraso de 30 a 59 dias TaxaDeEndividamento Pagamentos mensais de d\u00edvidas, pens\u00e3o aliment\u00edcia, custo de vida dividido pela renda RendaMensal Renda mensal NumeroDeLinhasDeCreditoEEmprestimosAbertos N\u00famero de empr\u00e9stimos abertos (parcelamento, como empr\u00e9stimo de carro ou hipoteca) NumeroDeVezes90DiasAtraso Quantas vezes o mutu\u00e1rio esteve atrasado por 90 dias ou mais NumeroDeEmprestimosOuLinhasImobiliarias N\u00famero de empr\u00e9stimos hipotec\u00e1rios e imobili\u00e1rios, incluindo linhas de cr\u00e9dito NumeroDeVezes60-89DiasAtrasoNaoPior N\u00famero de vezes que o mutu\u00e1rio apresentou atraso de 60 a 89 dias NumeroDeDependentes N\u00famero de dependentes na fam\u00edlia excluindo eles pr\u00f3prios (c\u00f4njuge, filhos etc.)"},{"location":"#planejamento-da-solucao","title":"Planejamento da solu\u00e7\u00e3o","text":""},{"location":"#produto-final","title":"Produto final","text":"<p>O que ser\u00e1 entregue efetivamente?</p> <ul> <li>Uma api onde ser\u00e1 necess\u00e1rio enviar os dados para realizar a previs\u00e3o.</li> <li>Um relatorio com o resultado do monitoramento feito pelo Evidently AI\"</li> </ul>"},{"location":"#ferramentas","title":"Ferramentas","text":"<p>Quais ferramentas ser\u00e3o usadas no processo?</p> <ul> <li>Visual Studio code;</li> <li>Jupyter Notebook;</li> <li>Git, Github;</li> <li>Python;</li> <li>Mlflow;</li> <li>Docker.</li> <li>Mkdock</li> </ul>"},{"location":"#resultados-para-o-negocio","title":"Resultados para o neg\u00f3cio","text":"<p>Foi desenvolvida uma API onde os clientes podem enviar os dados necess\u00e1rios para realizar a predi\u00e7\u00e3o de poss\u00edveis dificuldades financeiras nos pr\u00f3ximos dois anos.</p>"},{"location":"#conclusao","title":"Conclus\u00e3o","text":"<ul> <li>O objetivo do projeto foi alcan\u00e7ado, dado que os produtos de dados propostos foram gerados com sucesso.</li> </ul> <p>Confira o Resultado do monitoramento.</p>"},{"location":"dados/","title":"Dados","text":"Data <p>Essa pasta se refere ao ETL dos dados. Ela contem as classes:</p> <ul> <li>DataLoad</li> <li>DataPreprocess</li> <li>Transformation</li> <li>DataValidation</li> </ul> Data Load DataPreprocess DataTransformation DataValidation"},{"location":"dados/#src.data.data_load.DataLoad","title":"<code>src.data.data_load.DataLoad</code>","text":"<p>Classe para carregar dados de um arquivo CSV.</p> <p>Methods:</p> Name Description <code>load_data</code> <p>Carrega os dados do arquivo CSV especificado.</p> Source code in <code>src/data/data_load.py</code> <pre><code>class DataLoad:\n    \"\"\"\n    Classe para carregar dados de um arquivo CSV.\n\n    Methods:\n        load_data: Carrega os dados do arquivo CSV especificado.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        pass\n\n    def load_data(self, dataset_name: str) -&gt; pd.DataFrame:\n        \"\"\"Carrega os dados a partir do nome do dataser fornecido\n\n        Args:\n            dataset_name (str): O nome do arquivo CSV a ser carregado.\n\n        Returns:\n            dataframe: Um DataFrame contendo os dados carregados do arquivo CSV.\n        \"\"\"\n        logger.info(f\"Come\u00e7ando a carga dos dados com o nome {dataset_name}\")\n        try:\n            dataset = load_config_file().get(dataset_name)\n            if dataset is None:\n                raise ValueError(\n                    f\"Erro: O nome do dataset fornecido \u00e9 incorreto: {dataset}\"\n                )\n            path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n            dataset_path = os.path.join(path, \"data\", \"raw\", dataset)\n\n            loaded_data = pd.read_csv(dataset_path)\n            return loaded_data[load_config_file().get(\"columns_to_use\")]\n        except ValueError as ve:\n            logger.error(str(ve))\n        except Exception as e:\n            logger.error(f\"Erro inesperado: {str(e)}\")\n</code></pre>"},{"location":"dados/#src.data.data_load.DataLoad.load_data","title":"<code>load_data(dataset_name)</code>","text":"<p>Carrega os dados a partir do nome do dataser fornecido</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>O nome do arquivo CSV a ser carregado.</p> required <p>Returns:</p> Name Type Description <code>dataframe</code> <code>DataFrame</code> <p>Um DataFrame contendo os dados carregados do arquivo CSV.</p> Source code in <code>src/data/data_load.py</code> <pre><code>def load_data(self, dataset_name: str) -&gt; pd.DataFrame:\n    \"\"\"Carrega os dados a partir do nome do dataser fornecido\n\n    Args:\n        dataset_name (str): O nome do arquivo CSV a ser carregado.\n\n    Returns:\n        dataframe: Um DataFrame contendo os dados carregados do arquivo CSV.\n    \"\"\"\n    logger.info(f\"Come\u00e7ando a carga dos dados com o nome {dataset_name}\")\n    try:\n        dataset = load_config_file().get(dataset_name)\n        if dataset is None:\n            raise ValueError(\n                f\"Erro: O nome do dataset fornecido \u00e9 incorreto: {dataset}\"\n            )\n        path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n        dataset_path = os.path.join(path, \"data\", \"raw\", dataset)\n\n        loaded_data = pd.read_csv(dataset_path)\n        return loaded_data[load_config_file().get(\"columns_to_use\")]\n    except ValueError as ve:\n        logger.error(str(ve))\n    except Exception as e:\n        logger.error(f\"Erro inesperado: {str(e)}\")\n</code></pre>"},{"location":"dados/#src.data.data_preprocess.DataPreprocess","title":"<code>src.data.data_preprocess.DataPreprocess</code>","text":"<p>Classe para pr\u00e9-processamento de dados utilizando pipelines.</p> <p>Esta classe fornece m\u00e9todos para treinar e aplicar um pipeline de pr\u00e9-processamento aos dados fornecidos.</p> <p>Attributes:</p> Name Type Description <code>pipe</code> <code>Pipeline</code> <p>O pipeline de pr\u00e9-processamento a ser aplicado aos dados.</p> <code>trained_pipe</code> <code>Pipeline</code> <p>O pipeline treinado ap\u00f3s a execu\u00e7\u00e3o do m\u00e9todo train().</p> <p>Methods:</p> Name Description <code>train</code> <p>Treina o pipeline.</p> <code>transform</code> <p>Aplica o pipeline treinado aos dados</p> Source code in <code>src/data/data_preprocess.py</code> <pre><code>class DataPreprocess:\n    \"\"\"\n    Classe para pr\u00e9-processamento de dados utilizando pipelines.\n\n    Esta classe fornece m\u00e9todos para treinar e aplicar um pipeline de pr\u00e9-processamento\n    aos dados fornecidos.\n\n    Attributes:\n        pipe (Pipeline): O pipeline de pr\u00e9-processamento a ser aplicado aos dados.\n        trained_pipe (Pipeline): O pipeline treinado ap\u00f3s a execu\u00e7\u00e3o do m\u00e9todo train().\n\n    Methods:\n        train: Treina o pipeline.\n        transform: Aplica o pipeline treinado aos dados\n    \"\"\"\n\n    def __init__(self, pipe: Pipeline):\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe DataPreprocess.\n\n        Args:\n            pipe (Pipeline): O pipeline de pr\u00e9-processamento a ser aplicado aos dados.\n        \"\"\"\n        self.pipe = pipe\n        self.trained_pipe = None\n\n    def train(self, dataframe: pd.DataFrame):\n        \"\"\"\n        Treina o pipeline de pr\u00e9-processamento com os dados fornecidos.\n\n        Args:\n            dataframe (pd.DataFrame): O DataFrame contendo os dados de treinamento.\n        \"\"\"\n        logger.info(\"Pr\u00e9-processamento iniciou.\")\n        self.trained_pipe = self.pipe.fit(dataframe)\n        logger.info(\"pr\u00e9-processamento terminou\")\n\n    def transform(self, dataframe: pd.DataFrame):\n        \"\"\"\n        Aplica o pipeline treinado aos dados fornecidos.\n\n        Args:\n            dataframe (pd.DataFrame): O DataFrame contendo os dados a serem transformados.\n\n        Returns:\n            dataframe (pd.DataFrame): O DataFrame resultante ap\u00f3s a transforma\u00e7\u00e3o.\n        \"\"\"\n        if self.trained_pipe is None:\n            raise ValueError(\"Pipeline n\u00e3o foi treinado.\")\n\n        logger.info(\"Transforma\u00e7\u00e3o dos dados com preprocessador iniciou.\")\n        data_preprocessed = self.trained_pipe.transform(dataframe)\n        logger.info(\"Transforma\u00e7\u00e3o dos dados com preprocessador terminou.\")\n        return data_preprocessed\n</code></pre>"},{"location":"dados/#src.data.data_preprocess.DataPreprocess.__init__","title":"<code>__init__(pipe)</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe DataPreprocess.</p> <p>Parameters:</p> Name Type Description Default <code>pipe</code> <code>Pipeline</code> <p>O pipeline de pr\u00e9-processamento a ser aplicado aos dados.</p> required Source code in <code>src/data/data_preprocess.py</code> <pre><code>def __init__(self, pipe: Pipeline):\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe DataPreprocess.\n\n    Args:\n        pipe (Pipeline): O pipeline de pr\u00e9-processamento a ser aplicado aos dados.\n    \"\"\"\n    self.pipe = pipe\n    self.trained_pipe = None\n</code></pre>"},{"location":"dados/#src.data.data_preprocess.DataPreprocess.train","title":"<code>train(dataframe)</code>","text":"<p>Treina o pipeline de pr\u00e9-processamento com os dados fornecidos.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame contendo os dados de treinamento.</p> required Source code in <code>src/data/data_preprocess.py</code> <pre><code>def train(self, dataframe: pd.DataFrame):\n    \"\"\"\n    Treina o pipeline de pr\u00e9-processamento com os dados fornecidos.\n\n    Args:\n        dataframe (pd.DataFrame): O DataFrame contendo os dados de treinamento.\n    \"\"\"\n    logger.info(\"Pr\u00e9-processamento iniciou.\")\n    self.trained_pipe = self.pipe.fit(dataframe)\n    logger.info(\"pr\u00e9-processamento terminou\")\n</code></pre>"},{"location":"dados/#src.data.data_preprocess.DataPreprocess.transform","title":"<code>transform(dataframe)</code>","text":"<p>Aplica o pipeline treinado aos dados fornecidos.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame contendo os dados a serem transformados.</p> required <p>Returns:</p> Name Type Description <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame resultante ap\u00f3s a transforma\u00e7\u00e3o.</p> Source code in <code>src/data/data_preprocess.py</code> <pre><code>def transform(self, dataframe: pd.DataFrame):\n    \"\"\"\n    Aplica o pipeline treinado aos dados fornecidos.\n\n    Args:\n        dataframe (pd.DataFrame): O DataFrame contendo os dados a serem transformados.\n\n    Returns:\n        dataframe (pd.DataFrame): O DataFrame resultante ap\u00f3s a transforma\u00e7\u00e3o.\n    \"\"\"\n    if self.trained_pipe is None:\n        raise ValueError(\"Pipeline n\u00e3o foi treinado.\")\n\n    logger.info(\"Transforma\u00e7\u00e3o dos dados com preprocessador iniciou.\")\n    data_preprocessed = self.trained_pipe.transform(dataframe)\n    logger.info(\"Transforma\u00e7\u00e3o dos dados com preprocessador terminou.\")\n    return data_preprocessed\n</code></pre>"},{"location":"dados/#src.data.data_transformation.DataTransformation","title":"<code>src.data.data_transformation.DataTransformation</code>","text":"<p>Classe para realizar transforma\u00e7\u00f5es nos dados, incluindo divis\u00e3o em conjuntos de treino e teste.</p> <p>Esta classe oferece funcionalidades para manipula\u00e7\u00e3o de dados, incluindo a divis\u00e3o do conjunto de dados em subconjuntos de treino e teste.</p> <p>Attributes:</p> Name Type Description <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame contendo os dados a serem transformados.</p> <code>target_name</code> <code>str</code> <p>O nome da coluna alvo no DataFrame.</p> Source code in <code>src/data/data_transformation.py</code> <pre><code>class DataTransformation:\n    \"\"\"\n    Classe para realizar transforma\u00e7\u00f5es nos dados, incluindo divis\u00e3o em conjuntos de treino e teste.\n\n    Esta classe oferece funcionalidades para manipula\u00e7\u00e3o de dados, incluindo a divis\u00e3o do conjunto de dados em\n    subconjuntos de treino e teste.\n\n    Attributes:\n        dataframe (pd.DataFrame): O DataFrame contendo os dados a serem transformados.\n        target_name (str): O nome da coluna alvo no DataFrame.\n    \"\"\"\n\n    def __init__(self, dataframe: pd.DataFrame):\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe DataTransformation.\n\n        Args:\n            dataframe (pd.DataFrame): O DataFrame contendo os dados a serem transformados.\n\n        Methods:\n            train_test_spliting: Divide o conjunto de dados em subconjuntos de treino e teste.\n        \"\"\"\n        self.dataframe = dataframe\n        self.target_name = load_config_file().get(\"target_name\")\n\n    def train_test_spliting(\n        self,\n    ) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n        \"\"\"\n        Divide o conjunto de dados em subconjuntos de treino e teste.\n\n        Retorna os conjuntos de treino e teste para recursos (X) e alvos (y).\n\n        Returns:\n            tuple: Uma tupla contendo quatro elementos: X_train, X_valid, y_train, y_valid.\\n\n                X_train (pd.DataFrame): O conjunto de recursos de treino.\\n\n                X_valid (pd.DataFrame): O conjunto de recursos de teste.\\n\n                y_train (pd.Series): O conjunto de alvos de treino.\\n\n                y_valid (pd.Series): O conjunto de alvos de teste.\\n\n        \"\"\"\n        X = self.dataframe.drop(self.target_name, axis=1)\n        y = self.dataframe[self.target_name]\n\n        X_train, X_valid, y_train, y_valid = train_test_split(\n            X,\n            y,\n            test_size=load_config_file().get(\"test_size\"),\n            random_state=load_config_file().get(\"random_state\"),\n            stratify=y,\n        )\n\n        return X_train, X_valid, y_train, y_valid\n</code></pre>"},{"location":"dados/#src.data.data_transformation.DataTransformation.__init__","title":"<code>__init__(dataframe)</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe DataTransformation.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame contendo os dados a serem transformados.</p> required <p>Functions:</p> Name Description <code>train_test_spliting</code> <p>Divide o conjunto de dados em subconjuntos de treino e teste.</p> Source code in <code>src/data/data_transformation.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame):\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe DataTransformation.\n\n    Args:\n        dataframe (pd.DataFrame): O DataFrame contendo os dados a serem transformados.\n\n    Methods:\n        train_test_spliting: Divide o conjunto de dados em subconjuntos de treino e teste.\n    \"\"\"\n    self.dataframe = dataframe\n    self.target_name = load_config_file().get(\"target_name\")\n</code></pre>"},{"location":"dados/#src.data.data_transformation.DataTransformation.train_test_spliting","title":"<code>train_test_spliting()</code>","text":"<p>Divide o conjunto de dados em subconjuntos de treino e teste.</p> <p>Retorna os conjuntos de treino e teste para recursos (X) e alvos (y).</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[DataFrame, DataFrame, Series, Series]</code> <p>Uma tupla contendo quatro elementos: X_train, X_valid, y_train, y_valid.</p> <p>X_train (pd.DataFrame): O conjunto de recursos de treino.</p> <p>X_valid (pd.DataFrame): O conjunto de recursos de teste.</p> <p>y_train (pd.Series): O conjunto de alvos de treino.</p> <p>y_valid (pd.Series): O conjunto de alvos de teste.</p> Source code in <code>src/data/data_transformation.py</code> <pre><code>def train_test_spliting(\n    self,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n    \"\"\"\n    Divide o conjunto de dados em subconjuntos de treino e teste.\n\n    Retorna os conjuntos de treino e teste para recursos (X) e alvos (y).\n\n    Returns:\n        tuple: Uma tupla contendo quatro elementos: X_train, X_valid, y_train, y_valid.\\n\n            X_train (pd.DataFrame): O conjunto de recursos de treino.\\n\n            X_valid (pd.DataFrame): O conjunto de recursos de teste.\\n\n            y_train (pd.Series): O conjunto de alvos de treino.\\n\n            y_valid (pd.Series): O conjunto de alvos de teste.\\n\n    \"\"\"\n    X = self.dataframe.drop(self.target_name, axis=1)\n    y = self.dataframe[self.target_name]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(\n        X,\n        y,\n        test_size=load_config_file().get(\"test_size\"),\n        random_state=load_config_file().get(\"random_state\"),\n        stratify=y,\n    )\n\n    return X_train, X_valid, y_train, y_valid\n</code></pre>"},{"location":"dados/#src.data.data_validation.DataValidation","title":"<code>src.data.data_validation.DataValidation</code>","text":"<p>Classe de valida\u00e7\u00e3o dos dados.</p> <p>Esta classe oferece funcionalidades para validar a estrutura e as colunas de um DataFrame.</p> <p>Attributes:</p> Name Type Description <code>columns_to_use</code> <code>list</code> <p>Lista de colunas a serem utilizadas no DataFrame.</p> <p>Methods:</p> Name Description <code>check_shape_data</code> <p>Verifica se as colunas do DataFrame correspondem \u00e0 configura\u00e7\u00e3o definida.</p> <code>check_columns</code> <p>Verifica se as colunas do DataFrame atendem aos crit\u00e9rios definidos.</p> <code>run</code> <p>Executa as valida\u00e7\u00f5es da estrutura e das colunas do DataFrame.</p> Source code in <code>src/data/data_validation.py</code> <pre><code>class DataValidation:\n    \"\"\"\n    Classe de valida\u00e7\u00e3o dos dados.\n\n    Esta classe oferece funcionalidades para validar a estrutura e as colunas de um DataFrame.\n\n    Attributes:\n        columns_to_use (list): Lista de colunas a serem utilizadas no DataFrame.\n\n    Methods:\n        check_shape_data: Verifica se as colunas do DataFrame correspondem \u00e0 configura\u00e7\u00e3o definida.\n        check_columns: Verifica se as colunas do DataFrame atendem aos crit\u00e9rios definidos.\n        run: Executa as valida\u00e7\u00f5es da estrutura e das colunas do DataFrame.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe DataValidation.\n        \"\"\"\n        self.columns_to_use = load_config_file().get(\"columns_to_use\")\n\n    def check_shape_data(self, dataframe: pd.DataFrame) -&gt; bool:\n        \"\"\"\n        Verifica se as colunas do DataFrame correspondem \u00e0 configura\u00e7\u00e3o definida.\n\n        Args:\n            dataframe (pd.DataFrame): DataFrame a ser validado.\n\n        Returns:\n            bool: True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.\n        \"\"\"\n        try:\n            logger.info(\"Validacao iniciou\")\n            dataframe.columns = self.columns_to_use\n            return True\n        except Exception as e:\n            logger.error(f\"Validacao errou: {e}\")\n            return False\n\n    def check_columns(self, dataframe: pd.DataFrame) -&gt; bool:\n        \"\"\"\n        Verifica se as colunas do DataFrame atendem aos crit\u00e9rios definidos.\n\n        Args:\n            dataframe (pd.DataFrame): DataFrame a ser validado.\n\n        Returns:\n            bool: True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.\n        \"\"\"\n        schema = DataFrameSchema(\n            {\n                \"target\": Column(\n                    int,\n                    Check.isin([0, 1]),\n                    Check(lambda x: x &gt; 0),\n                    coerce=True,\n                ),\n                \"TaxaDeUtilizacaoDeLinhasNaoGarantidas\": Column(\n                    float, nullable=True\n                ),\n                \"Idade\": Column(int, nullable=True),\n                \"NumeroDeVezes30-59DiasAtrasoNaoPior\": Column(\n                    int, nullable=True\n                ),\n                \"TaxaDeEndividamento\": Column(float, nullable=True),\n                \"RendaMensal\": Column(float, nullable=True),\n                \"NumeroDeLinhasDeCreditoEEmprestimosAbertos\": Column(\n                    int, nullable=True\n                ),\n                \"NumeroDeVezes90DiasAtraso\": Column(int, nullable=True),\n                \"NumeroDeEmprestimosOuLinhasImobiliarias\": Column(\n                    int, nullable=True\n                ),\n                \"NumeroDeVezes60-89DiasAtrasoNaoPior\": Column(\n                    int, nullable=True\n                ),\n                \"NumeroDeDependentes\": Column(float, nullable=True),\n            }\n        )\n        try:\n            schema.validate(dataframe)\n            logger.info(\"Validation columns passed...\")\n            return True\n        except pandera.errors.SchemaErrors as exc:\n            logger.error(\"Validation columns failed...\")\n            pandera.display(exc.failure_cases)\n        return False\n\n    def run(self, dataframe: pd.DataFrame) -&gt; bool:\n        \"\"\"\n        Executa as valida\u00e7\u00f5es da estrutura e das colunas do DataFrame.\n\n        Args:\n            dataframe (pd.DataFrame): DataFrame a ser validado.\n\n        Returns:\n            bool: True se todas as valida\u00e7\u00f5es forem bem-sucedidas, False caso contr\u00e1rio.\n        \"\"\"\n        if self.check_shape_data(dataframe) and self.check_columns(dataframe):\n            logger.info(\"Valida\u00e7\u00e3o com sucesso.\")\n            return True\n        else:\n            logger.error(\"Valida\u00e7\u00e3o falhou.\")\n            return False\n</code></pre>"},{"location":"dados/#src.data.data_validation.DataValidation.__init__","title":"<code>__init__()</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe DataValidation.</p> Source code in <code>src/data/data_validation.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe DataValidation.\n    \"\"\"\n    self.columns_to_use = load_config_file().get(\"columns_to_use\")\n</code></pre>"},{"location":"dados/#src.data.data_validation.DataValidation.check_columns","title":"<code>check_columns(dataframe)</code>","text":"<p>Verifica se as colunas do DataFrame atendem aos crit\u00e9rios definidos.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>DataFrame a ser validado.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.</p> Source code in <code>src/data/data_validation.py</code> <pre><code>def check_columns(self, dataframe: pd.DataFrame) -&gt; bool:\n    \"\"\"\n    Verifica se as colunas do DataFrame atendem aos crit\u00e9rios definidos.\n\n    Args:\n        dataframe (pd.DataFrame): DataFrame a ser validado.\n\n    Returns:\n        bool: True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.\n    \"\"\"\n    schema = DataFrameSchema(\n        {\n            \"target\": Column(\n                int,\n                Check.isin([0, 1]),\n                Check(lambda x: x &gt; 0),\n                coerce=True,\n            ),\n            \"TaxaDeUtilizacaoDeLinhasNaoGarantidas\": Column(\n                float, nullable=True\n            ),\n            \"Idade\": Column(int, nullable=True),\n            \"NumeroDeVezes30-59DiasAtrasoNaoPior\": Column(\n                int, nullable=True\n            ),\n            \"TaxaDeEndividamento\": Column(float, nullable=True),\n            \"RendaMensal\": Column(float, nullable=True),\n            \"NumeroDeLinhasDeCreditoEEmprestimosAbertos\": Column(\n                int, nullable=True\n            ),\n            \"NumeroDeVezes90DiasAtraso\": Column(int, nullable=True),\n            \"NumeroDeEmprestimosOuLinhasImobiliarias\": Column(\n                int, nullable=True\n            ),\n            \"NumeroDeVezes60-89DiasAtrasoNaoPior\": Column(\n                int, nullable=True\n            ),\n            \"NumeroDeDependentes\": Column(float, nullable=True),\n        }\n    )\n    try:\n        schema.validate(dataframe)\n        logger.info(\"Validation columns passed...\")\n        return True\n    except pandera.errors.SchemaErrors as exc:\n        logger.error(\"Validation columns failed...\")\n        pandera.display(exc.failure_cases)\n    return False\n</code></pre>"},{"location":"dados/#src.data.data_validation.DataValidation.check_shape_data","title":"<code>check_shape_data(dataframe)</code>","text":"<p>Verifica se as colunas do DataFrame correspondem \u00e0 configura\u00e7\u00e3o definida.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>DataFrame a ser validado.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.</p> Source code in <code>src/data/data_validation.py</code> <pre><code>def check_shape_data(self, dataframe: pd.DataFrame) -&gt; bool:\n    \"\"\"\n    Verifica se as colunas do DataFrame correspondem \u00e0 configura\u00e7\u00e3o definida.\n\n    Args:\n        dataframe (pd.DataFrame): DataFrame a ser validado.\n\n    Returns:\n        bool: True se a valida\u00e7\u00e3o for bem-sucedida, False caso contr\u00e1rio.\n    \"\"\"\n    try:\n        logger.info(\"Validacao iniciou\")\n        dataframe.columns = self.columns_to_use\n        return True\n    except Exception as e:\n        logger.error(f\"Validacao errou: {e}\")\n        return False\n</code></pre>"},{"location":"dados/#src.data.data_validation.DataValidation.run","title":"<code>run(dataframe)</code>","text":"<p>Executa as valida\u00e7\u00f5es da estrutura e das colunas do DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>DataFrame a ser validado.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se todas as valida\u00e7\u00f5es forem bem-sucedidas, False caso contr\u00e1rio.</p> Source code in <code>src/data/data_validation.py</code> <pre><code>def run(self, dataframe: pd.DataFrame) -&gt; bool:\n    \"\"\"\n    Executa as valida\u00e7\u00f5es da estrutura e das colunas do DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): DataFrame a ser validado.\n\n    Returns:\n        bool: True se todas as valida\u00e7\u00f5es forem bem-sucedidas, False caso contr\u00e1rio.\n    \"\"\"\n    if self.check_shape_data(dataframe) and self.check_columns(dataframe):\n        logger.info(\"Valida\u00e7\u00e3o com sucesso.\")\n        return True\n    else:\n        logger.error(\"Valida\u00e7\u00e3o falhou.\")\n        return False\n</code></pre>"},{"location":"evaluation/","title":"Evaluation","text":"ModelEvaluation"},{"location":"evaluation/#src.evaluation.classifier_eval.ModelEvaluation","title":"<code>src.evaluation.classifier_eval.ModelEvaluation</code>","text":"<p>Classe para avalia\u00e7\u00e3o de modelos de machine learning.</p> <p>Esta classe fornece m\u00e9todos para avaliar a performance de modelos de machine learning, incluindo valida\u00e7\u00e3o cruzada e m\u00e9tricas de avalia\u00e7\u00e3o.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>ndarray</code> <p>O modelo de machine learning a ser avaliado.</p> <code>x</code> <code>DataFrame</code> <p>O DataFrame contendo os recursos de entrada.</p> <code>y</code> <code>DataFrame</code> <p>O DataFrame contendo os r\u00f3tulos alvo.</p> <code>n_splits</code> <code>int</code> <p>O n\u00famero de divis\u00f5es para a valida\u00e7\u00e3o cruzada. Padr\u00e3o \u00e9 5.</p> <p>Methods:</p> Name Description <code>cross_val_evaluate</code> <p>Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.</p> <code>evaluate_predictions</code> <p>Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.</p> <code>roc_auc_scorer</code> <p>Calcula a m\u00e9trica AUC-ROC para o modelo dado os dados de entrada e sa\u00edda.</p> Source code in <code>src/evaluation/classifier_eval.py</code> <pre><code>class ModelEvaluation:\n    \"\"\"\n    Classe para avalia\u00e7\u00e3o de modelos de machine learning.\n\n    Esta classe fornece m\u00e9todos para avaliar a performance de modelos de machine learning,\n    incluindo valida\u00e7\u00e3o cruzada e m\u00e9tricas de avalia\u00e7\u00e3o.\n\n    Attributes:\n        model (np.ndarray): O modelo de machine learning a ser avaliado.\n        x (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n        y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n        n_splits (int, optional): O n\u00famero de divis\u00f5es para a valida\u00e7\u00e3o cruzada. Padr\u00e3o \u00e9 5.\n\n    Methods:\n        cross_val_evaluate: Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.\n        evaluate_predictions: Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.\n        roc_auc_scorer: Calcula a m\u00e9trica AUC-ROC para o modelo dado os dados de entrada e sa\u00edda.\n\n    \"\"\"\n\n    def __init__(\n        self, model: Any, x: pd.DataFrame, y: pd.DataFrame, n_splits: int = 5\n    ) -&gt; None:\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe ModelEvaluation.\n\n        Args:\n            model: O modelo de machine learning a ser avaliado.\n            x (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n            y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n            n_splits (int, opcional): O n\u00famero de divis\u00f5es para a valida\u00e7\u00e3o cruzada. Padr\u00e3o \u00e9 5.\n        \"\"\"\n\n        self.model = model\n        self.x = x\n        self.y = y\n        self.n_splits = n_splits\n\n    def cross_val_evaluate(self) -&gt; List[float]:\n        \"\"\"\n        Realiza a valida\u00e7\u00e3o cruzada do modelo.\n\n        Retorna uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.\n\n        Returns:\n            List[float]: Uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.\n        \"\"\"\n\n        logger.info(\"Iniciou a valida\u00e7\u00e3o cruzada.\")\n        skf = StratifiedKFold(\n            n_splits=self.n_splits,\n            shuffle=True,\n            random_state=load_config_file().get(\"random_state\"),\n        )\n\n        scores = cross_val_score(\n            self.model, self.x, self.y, cv=skf, scoring=\"roc_auc\"\n        )\n        return scores\n\n    def roc_auc_scorer(\n        self, model: Any, x: pd.DataFrame, y: pd.DataFrame\n    ) -&gt; float:\n        \"\"\"\n        Calcula a m\u00e9trica AUC-ROC para o modelo dado os dados de entrada e sa\u00edda.\n\n        Args:\n            model: O modelo de machine learning.\n            x (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n            y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n\n        Returns:\n            float: O valor da m\u00e9trica AUC-ROC.\n        \"\"\"\n\n        y_pred = model.predict_proba(x)[:, 1]\n        return roc_auc_score(y, y_pred)\n\n    @staticmethod\n    def evaluate_predictions(\n        y_true: pd.DataFrame, y_pred_proba: pd.DataFrame\n    ) -&gt; float:\n        \"\"\"\n        Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.\n\n        Args:\n            y_true (pd.DataFrame): O array contendo os r\u00f3tulos alvo verdadeiros.\n            y_pred_proba (pd.DataFrame): O array contendo as probabilidades preditas para as classes positivas.\n\n        Returns:\n            float: O valor da m\u00e9trica AUC-ROC.\n        \"\"\"\n\n        logger.info(\"Iniciou a valida\u00e7\u00e3o do modelo.\")\n        return roc_auc_score(y_true, y_pred_proba)\n</code></pre>"},{"location":"evaluation/#src.evaluation.classifier_eval.ModelEvaluation.__init__","title":"<code>__init__(model, x, y, n_splits=5)</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe ModelEvaluation.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>O modelo de machine learning a ser avaliado.</p> required <code>x</code> <code>DataFrame</code> <p>O DataFrame contendo os recursos de entrada.</p> required <code>y</code> <code>DataFrame</code> <p>O DataFrame contendo os r\u00f3tulos alvo.</p> required <code>n_splits</code> <code>(int, opcional)</code> <p>O n\u00famero de divis\u00f5es para a valida\u00e7\u00e3o cruzada. Padr\u00e3o \u00e9 5.</p> <code>5</code> Source code in <code>src/evaluation/classifier_eval.py</code> <pre><code>def __init__(\n    self, model: Any, x: pd.DataFrame, y: pd.DataFrame, n_splits: int = 5\n) -&gt; None:\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe ModelEvaluation.\n\n    Args:\n        model: O modelo de machine learning a ser avaliado.\n        x (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n        y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n        n_splits (int, opcional): O n\u00famero de divis\u00f5es para a valida\u00e7\u00e3o cruzada. Padr\u00e3o \u00e9 5.\n    \"\"\"\n\n    self.model = model\n    self.x = x\n    self.y = y\n    self.n_splits = n_splits\n</code></pre>"},{"location":"evaluation/#src.evaluation.classifier_eval.ModelEvaluation.cross_val_evaluate","title":"<code>cross_val_evaluate()</code>","text":"<p>Realiza a valida\u00e7\u00e3o cruzada do modelo.</p> <p>Retorna uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.</p> <p>Returns:</p> Type Description <code>List[float]</code> <p>List[float]: Uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.</p> Source code in <code>src/evaluation/classifier_eval.py</code> <pre><code>def cross_val_evaluate(self) -&gt; List[float]:\n    \"\"\"\n    Realiza a valida\u00e7\u00e3o cruzada do modelo.\n\n    Retorna uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.\n\n    Returns:\n        List[float]: Uma lista contendo os valores de AUC-ROC para cada fold da valida\u00e7\u00e3o cruzada.\n    \"\"\"\n\n    logger.info(\"Iniciou a valida\u00e7\u00e3o cruzada.\")\n    skf = StratifiedKFold(\n        n_splits=self.n_splits,\n        shuffle=True,\n        random_state=load_config_file().get(\"random_state\"),\n    )\n\n    scores = cross_val_score(\n        self.model, self.x, self.y, cv=skf, scoring=\"roc_auc\"\n    )\n    return scores\n</code></pre>"},{"location":"evaluation/#src.evaluation.classifier_eval.ModelEvaluation.evaluate_predictions","title":"<code>evaluate_predictions(y_true, y_pred_proba)</code>  <code>staticmethod</code>","text":"<p>Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>DataFrame</code> <p>O array contendo os r\u00f3tulos alvo verdadeiros.</p> required <code>y_pred_proba</code> <code>DataFrame</code> <p>O array contendo as probabilidades preditas para as classes positivas.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>O valor da m\u00e9trica AUC-ROC.</p> Source code in <code>src/evaluation/classifier_eval.py</code> <pre><code>@staticmethod\ndef evaluate_predictions(\n    y_true: pd.DataFrame, y_pred_proba: pd.DataFrame\n) -&gt; float:\n    \"\"\"\n    Avalia as predi\u00e7\u00f5es do modelo usando a m\u00e9trica AUC-ROC.\n\n    Args:\n        y_true (pd.DataFrame): O array contendo os r\u00f3tulos alvo verdadeiros.\n        y_pred_proba (pd.DataFrame): O array contendo as probabilidades preditas para as classes positivas.\n\n    Returns:\n        float: O valor da m\u00e9trica AUC-ROC.\n    \"\"\"\n\n    logger.info(\"Iniciou a valida\u00e7\u00e3o do modelo.\")\n    return roc_auc_score(y_true, y_pred_proba)\n</code></pre>"},{"location":"evaluation/#src.evaluation.classifier_eval.ModelEvaluation.roc_auc_scorer","title":"<code>roc_auc_scorer(model, x, y)</code>","text":"<p>Calcula a m\u00e9trica AUC-ROC para o modelo dado os dados de entrada e sa\u00edda.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>O modelo de machine learning.</p> required <code>x</code> <code>DataFrame</code> <p>O DataFrame contendo os recursos de entrada.</p> required <code>y</code> <code>DataFrame</code> <p>O DataFrame contendo os r\u00f3tulos alvo.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>O valor da m\u00e9trica AUC-ROC.</p> Source code in <code>src/evaluation/classifier_eval.py</code> <pre><code>def roc_auc_scorer(\n    self, model: Any, x: pd.DataFrame, y: pd.DataFrame\n) -&gt; float:\n    \"\"\"\n    Calcula a m\u00e9trica AUC-ROC para o modelo dado os dados de entrada e sa\u00edda.\n\n    Args:\n        model: O modelo de machine learning.\n        x (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n        y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n\n    Returns:\n        float: O valor da m\u00e9trica AUC-ROC.\n    \"\"\"\n\n    y_pred = model.predict_proba(x)[:, 1]\n    return roc_auc_score(y, y_pred)\n</code></pre>"},{"location":"monitoring/","title":"Monitoring","text":"Monitoring <p>Classe para monitoramento de modelo.</p> <p>Esta classe carrega os dados de previs\u00e3o e os dados de treinamento, calcula m\u00e9tricas de monitoramento de modelo, e gera um relat\u00f3rio de monitoramento.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>A consulta SQL para recuperar os dados de previs\u00e3o.</p> Source code in <code>src/monitoring/monitor.py</code> <pre><code>class ModelMonitoring:\n    \"\"\"\n    Classe para monitoramento de modelo.\n\n    Esta classe carrega os dados de previs\u00e3o e os dados de treinamento, calcula m\u00e9tricas de\n    monitoramento de modelo, e gera um relat\u00f3rio de monitoramento.\n\n    Attributes:\n        query (str): A consulta SQL para recuperar os dados de previs\u00e3o.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe ModelMonitoring.\n        \"\"\"\n\n        self.query = \"SELECT * FROM predictions\"\n\n    def get_pred_data(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Obt\u00e9m os dados de previs\u00e3o do banco de dados.\n\n        Returns:\n            pd.DataFrame: O DataFrame contendo os dados de previs\u00e3o.\n        \"\"\"\n\n        conn = sqlite3.connect(\"preds.db\")\n        df_pred = pd.read_sql_query(self.query, conn)\n        conn.close()\n        return df_pred\n\n    def get_training_data(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Obt\u00e9m os dados de treinamento.\n\n        Returns:\n            pd.DataFrame: O DataFrame contendo os dados de treinamento.\n        \"\"\"\n\n        dl = DataLoad()\n        df_train = dl.load_data(\"train_dataset_name\")\n        return df_train\n\n    def run(self) -&gt; None:\n        \"\"\"\n        Executa o monitoramento do modelo, calcula m\u00e9tricas e gera um relat\u00f3rio.\n\n        Returns:\n            None\n        \"\"\"\n\n        df_cur = self.get_pred_data()  # dados atuais\n        df_ref = self.get_training_data().drop(\n            load_config_file().get(\"target_name\"), axis=1\n        )  # dados referencia\n\n        model_card = Report(\n            metrics=[\n                DatasetSummaryMetric(),\n                DataDriftPreset(),\n                DatasetMissingValuesMetric(),\n            ]\n        )\n\n        model_card.run(reference_data=df_ref, current_data=df_cur)\n        model_card.save_html(\"projeto/docs/model_monitoring_report.html\")\n</code></pre>"},{"location":"monitoring/#src.monitoring.monitor.ModelMonitoring.__init__","title":"<code>__init__()</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe ModelMonitoring.</p> Source code in <code>src/monitoring/monitor.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe ModelMonitoring.\n    \"\"\"\n\n    self.query = \"SELECT * FROM predictions\"\n</code></pre>"},{"location":"monitoring/#src.monitoring.monitor.ModelMonitoring.get_pred_data","title":"<code>get_pred_data()</code>","text":"<p>Obt\u00e9m os dados de previs\u00e3o do banco de dados.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: O DataFrame contendo os dados de previs\u00e3o.</p> Source code in <code>src/monitoring/monitor.py</code> <pre><code>def get_pred_data(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Obt\u00e9m os dados de previs\u00e3o do banco de dados.\n\n    Returns:\n        pd.DataFrame: O DataFrame contendo os dados de previs\u00e3o.\n    \"\"\"\n\n    conn = sqlite3.connect(\"preds.db\")\n    df_pred = pd.read_sql_query(self.query, conn)\n    conn.close()\n    return df_pred\n</code></pre>"},{"location":"monitoring/#src.monitoring.monitor.ModelMonitoring.get_training_data","title":"<code>get_training_data()</code>","text":"<p>Obt\u00e9m os dados de treinamento.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: O DataFrame contendo os dados de treinamento.</p> Source code in <code>src/monitoring/monitor.py</code> <pre><code>def get_training_data(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Obt\u00e9m os dados de treinamento.\n\n    Returns:\n        pd.DataFrame: O DataFrame contendo os dados de treinamento.\n    \"\"\"\n\n    dl = DataLoad()\n    df_train = dl.load_data(\"train_dataset_name\")\n    return df_train\n</code></pre>"},{"location":"monitoring/#src.monitoring.monitor.ModelMonitoring.run","title":"<code>run()</code>","text":"<p>Executa o monitoramento do modelo, calcula m\u00e9tricas e gera um relat\u00f3rio.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/monitoring/monitor.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"\n    Executa o monitoramento do modelo, calcula m\u00e9tricas e gera um relat\u00f3rio.\n\n    Returns:\n        None\n    \"\"\"\n\n    df_cur = self.get_pred_data()  # dados atuais\n    df_ref = self.get_training_data().drop(\n        load_config_file().get(\"target_name\"), axis=1\n    )  # dados referencia\n\n    model_card = Report(\n        metrics=[\n            DatasetSummaryMetric(),\n            DataDriftPreset(),\n            DatasetMissingValuesMetric(),\n        ]\n    )\n\n    model_card.run(reference_data=df_ref, current_data=df_cur)\n    model_card.save_html(\"projeto/docs/model_monitoring_report.html\")\n</code></pre>"},{"location":"predict/","title":"Predict","text":"Predict <p>Classe para realizar predi\u00e7\u00f5es usando um modelo em um endpoint.</p> <p>Esta classe envia os dados para um endpoint do mlflow, obt\u00e9m as predi\u00e7\u00f5es e salva os resultados na base de dados.</p> <p>Attributes:</p> Name Type Description <code>dataframe</code> <code>DataFrame</code> <p>O DataFrame contendo os dados a serem preditos.</p> <p>Methods:</p> Name Description <code>run</code> <p>Executa o processo de predi\u00e7\u00e3o.</p> Source code in <code>src/predict/predict.py</code> <pre><code>class Predict:\n    \"\"\"\n    Classe para realizar predi\u00e7\u00f5es usando um modelo em um endpoint.\n\n    Esta classe envia os dados para um endpoint do mlflow, obt\u00e9m as predi\u00e7\u00f5es e salva os resultados\n    na base de dados.\n\n    Attributes:\n        dataframe (pd.DataFrame): O DataFrame contendo os dados a serem preditos.\n\n    Methods:\n        run: Executa o processo de predi\u00e7\u00e3o.\n    \"\"\"\n\n    def __init__(self, dataframe: pd.DataFrame):\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe Predict.\n\n        Args:\n            dataframe (pd.DataFrame): O DataFrame contendo os dados a serem preditos.\n        \"\"\"\n\n        self.dataframe = dataframe\n        self.endpoint = \"http://127.0.0.1:5001/invocations\"\n\n    def run(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Executa o processo de predi\u00e7\u00e3o.\n\n        Retorna um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n\n        Returns:\n            pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n        \"\"\"\n\n        logger.info(\"inciando a predi\u00e7\u00e3o.\")\n        to_inderence = {\n            \"dataframe_split\": {\n                \"columns\": self.dataframe.columns.to_list(),\n                \"data\": self.dataframe.replace(np.nan, None).values.tolist(),\n            }\n        }\n        response = requests.post(self.endpoint, json=to_inderence)\n        logger.info(\"Predi\u00e7\u00f5es finalizadas.\")\n\n        probabilities = np.array(\n            json.loads(response.text).get(\"predictions\", [])\n        )[:, 1]\n\n        df_probs = self._results(probabilities)\n        self._capture_inputs_and_predictions(to_inderence, df_probs)\n\n        logger.info(\"Resultados salvo na base de dados.\")\n        return df_probs\n\n    def _capture_inputs_and_predictions(\n        self, inputs: Dict[str, Dict[str, Any]], preds: pd.DataFrame\n    ) -&gt; None:\n        \"\"\"\n        Captura os inputs e as predi\u00e7\u00f5es e salva na base de dados.\n\n        Args:\n            inputs (Dict[str, Dict[str, Any]]): Dados de entrada para a predi\u00e7\u00e3o.\n            preds (pd.DataFrame): Probabilidades das predi\u00e7\u00f5es.\n\n        Returns:\n            None\n        \"\"\"\n\n        input_df = pd.DataFrame(\n            inputs[\"dataframe_split\"][\"data\"],\n            columns=inputs[\"dataframe_split\"][\"columns\"],\n        )\n        input_df[\"preds_prob\"] = preds\n\n        # armazena no database\n        self._store_in_database(input_df)\n\n    def _store_in_database(self, input_df: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Armazena os dados na base de dados.\n\n        Args:\n            input_df (pd.DataFrame): DataFrame contendo os dados a serem armazenados.\n\n        Returns:\n            None\n        \"\"\"\n\n        input_df.to_sql(\"predictions\", conn, if_exists=\"append\", index=False)\n        conn.commit()\n        conn.close()\n\n    def _results(self, probabilities: np.array) -&gt; pd.DataFrame:\n        \"\"\"\n        Cria um DataFrame com as probabilidades das predi\u00e7\u00f5es.\n\n        Args:\n            probabilities (np.array): Array contendo as probabilidades das predi\u00e7\u00f5es.\n\n        Returns:\n            pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n        \"\"\"\n\n        df_results = pd.DataFrame()\n        logger.info(\"Salvando as probabilidades.\")\n        df_results[\"probabilities_default\"] = probabilities\n        return df_results\n</code></pre>"},{"location":"predict/#src.predict.predict.Predict.run","title":"<code>run()</code>","text":"<p>Executa o processo de predi\u00e7\u00e3o.</p> <p>Retorna um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.</p> Source code in <code>src/predict/predict.py</code> <pre><code>def run(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Executa o processo de predi\u00e7\u00e3o.\n\n    Retorna um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n\n    Returns:\n        pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n    \"\"\"\n\n    logger.info(\"inciando a predi\u00e7\u00e3o.\")\n    to_inderence = {\n        \"dataframe_split\": {\n            \"columns\": self.dataframe.columns.to_list(),\n            \"data\": self.dataframe.replace(np.nan, None).values.tolist(),\n        }\n    }\n    response = requests.post(self.endpoint, json=to_inderence)\n    logger.info(\"Predi\u00e7\u00f5es finalizadas.\")\n\n    probabilities = np.array(\n        json.loads(response.text).get(\"predictions\", [])\n    )[:, 1]\n\n    df_probs = self._results(probabilities)\n    self._capture_inputs_and_predictions(to_inderence, df_probs)\n\n    logger.info(\"Resultados salvo na base de dados.\")\n    return df_probs\n</code></pre>"},{"location":"predict/#src.predict.predict.Predict._capture_inputs_and_predictions","title":"<code>_capture_inputs_and_predictions(inputs, preds)</code>","text":"<p>Captura os inputs e as predi\u00e7\u00f5es e salva na base de dados.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Dict[str, Dict[str, Any]]</code> <p>Dados de entrada para a predi\u00e7\u00e3o.</p> required <code>preds</code> <code>DataFrame</code> <p>Probabilidades das predi\u00e7\u00f5es.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/predict/predict.py</code> <pre><code>def _capture_inputs_and_predictions(\n    self, inputs: Dict[str, Dict[str, Any]], preds: pd.DataFrame\n) -&gt; None:\n    \"\"\"\n    Captura os inputs e as predi\u00e7\u00f5es e salva na base de dados.\n\n    Args:\n        inputs (Dict[str, Dict[str, Any]]): Dados de entrada para a predi\u00e7\u00e3o.\n        preds (pd.DataFrame): Probabilidades das predi\u00e7\u00f5es.\n\n    Returns:\n        None\n    \"\"\"\n\n    input_df = pd.DataFrame(\n        inputs[\"dataframe_split\"][\"data\"],\n        columns=inputs[\"dataframe_split\"][\"columns\"],\n    )\n    input_df[\"preds_prob\"] = preds\n\n    # armazena no database\n    self._store_in_database(input_df)\n</code></pre>"},{"location":"predict/#src.predict.predict.Predict._store_in_database","title":"<code>_store_in_database(input_df)</code>","text":"<p>Armazena os dados na base de dados.</p> <p>Parameters:</p> Name Type Description Default <code>input_df</code> <code>DataFrame</code> <p>DataFrame contendo os dados a serem armazenados.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/predict/predict.py</code> <pre><code>def _store_in_database(self, input_df: pd.DataFrame) -&gt; None:\n    \"\"\"\n    Armazena os dados na base de dados.\n\n    Args:\n        input_df (pd.DataFrame): DataFrame contendo os dados a serem armazenados.\n\n    Returns:\n        None\n    \"\"\"\n\n    input_df.to_sql(\"predictions\", conn, if_exists=\"append\", index=False)\n    conn.commit()\n    conn.close()\n</code></pre>"},{"location":"predict/#src.predict.predict.Predict._results","title":"<code>_results(probabilities)</code>","text":"<p>Cria um DataFrame com as probabilidades das predi\u00e7\u00f5es.</p> <p>Parameters:</p> Name Type Description Default <code>probabilities</code> <code>array</code> <p>Array contendo as probabilidades das predi\u00e7\u00f5es.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.</p> Source code in <code>src/predict/predict.py</code> <pre><code>def _results(self, probabilities: np.array) -&gt; pd.DataFrame:\n    \"\"\"\n    Cria um DataFrame com as probabilidades das predi\u00e7\u00f5es.\n\n    Args:\n        probabilities (np.array): Array contendo as probabilidades das predi\u00e7\u00f5es.\n\n    Returns:\n        pd.DataFrame: Um DataFrame contendo as probabilidades das predi\u00e7\u00f5es.\n    \"\"\"\n\n    df_results = pd.DataFrame()\n    logger.info(\"Salvando as probabilidades.\")\n    df_results[\"probabilities_default\"] = probabilities\n    return df_results\n</code></pre>"},{"location":"train/","title":"Train","text":"Train"},{"location":"train/#src.train.train.TrainModels","title":"<code>src.train.train.TrainModels</code>","text":"<p>Classe para treinamento de modelos de machine learning.</p> <p>Esta classe utiliza o MLflow para treinar um modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros obtidos durante a execu\u00e7\u00e3o da busca do MLflow.</p> <p>Attributes:</p> Name Type Description <code>dados_X</code> <code>DataFrame</code> <p>O DataFrame contendo os recursos de entrada.</p> <code>dados_y</code> <code>DataFrame</code> <p>O DataFrame contendo os r\u00f3tulos alvo.</p> <p>Methods:</p> Name Description <code>get_best_model</code> <p>Obt\u00e9m os melhores par\u00e2metros e a m\u00e9trica de desempenho do melhor modelo do MLflow.</p> <code>run</code> <p>Executa o treinamento do modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros obtidos durante a busca do MLflow.</p> Source code in <code>src/train/train.py</code> <pre><code>class TrainModels:\n    \"\"\"\n    Classe para treinamento de modelos de machine learning.\n\n    Esta classe utiliza o MLflow para treinar um modelo de Regress\u00e3o Log\u00edstica com\n    os melhores par\u00e2metros obtidos durante a execu\u00e7\u00e3o da busca do MLflow.\n\n    Attributes:\n        dados_X (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n        dados_y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n\n    Methods:\n        get_best_model: Obt\u00e9m os melhores par\u00e2metros e a m\u00e9trica de desempenho do melhor modelo do MLflow.\n        run: Executa o treinamento do modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros obtidos durante a busca do MLflow.\n    \"\"\"\n\n    def __init__(self, dados_X: pd.DataFrame, dados_y: pd.DataFrame):\n        \"\"\"\n        Inicializa uma inst\u00e2ncia da classe TrainModels.\n\n        Args:\n            dados_X (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n            dados_y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n        \"\"\"\n\n        self.dados_X = dados_X\n        self.dados_y = dados_y\n        self.model_name = load_config_file().get(\"model_name\")\n\n    def get_best_model(self) -&gt; Tuple[float, pd.DataFrame]:\n        \"\"\"\n        Obt\u00e9m os melhores par\u00e2metros e a m\u00e9trica de desempenho do melhor modelo do MLflow.\n\n        Returns:\n            Uma tupla contendo a melhor m\u00e9trica de desempenho e os melhores par\u00e2metros do modelo.\n        \"\"\"\n\n        logger.info(\"Obtendo o melhor modelo do MLFlow\")\n        df_mlflow = mlflow.search_runs(\n            filter_string=\"metrics.valid_roc_auc &lt; 1\"\n        ).sort_values(\"metrics.valid_roc_auc\", ascending=False)\n        run_id = df_mlflow.loc[df_mlflow[\"metrics.valid_roc_auc\"].idxmax()][\n            \"run_id\"\n        ]\n        df_best_params = df_mlflow.loc[df_mlflow[\"run_id\"] == run_id][\n            [\n                \"params.class_weight\",\n                \"params.discretizer\",\n                \"params.warm_start\",\n                \"params.imputer\",\n                \"params.solver\",\n                \"params.scaler\",\n                \"params.max_iter\",\n                \"params.fit_intercept\",\n                \"params.tol\",\n                \"params.multi_class\",\n                \"params.C\",\n            ]\n        ]\n        best_roc_auc = df_mlflow.loc[\n            df_mlflow[\"metrics.valid_roc_auc\"].idxmax()\n        ][\"metrics.valid_roc_auc\"]\n\n        return best_roc_auc, df_best_params\n\n    def run(self) -&gt; None:\n        \"\"\"\n        Executa o treinamento do modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros\n        obtidos durante a busca do MLflow.\n        \"\"\"\n\n        _, df_best_params = self.get_best_model()\n        logger.info(f\"Iniciando o treinamento do modelo: {self.model_name}\")\n\n        with mlflow.start_run(run_name=\"final_model\"):\n            mlflow.set_tag(\"model_name\", self.model_name)\n\n            model = LogisticRegression(\n                warm_start=eval(df_best_params[\"params.warm_start\"].values[0]),\n                multi_class=df_best_params[\"params.multi_class\"].values[0],\n                class_weight=df_best_params[\"params.class_weight\"].values[0],\n                max_iter=int(df_best_params[\"params.max_iter\"].values[0]),\n                C=float(df_best_params[\"params.C\"].values[0]),\n                solver=df_best_params[\"params.solver\"].values[0],\n                tol=float(df_best_params[\"params.tol\"].values[0]),\n            )\n\n        pipe = Pipeline(\n            [\n                (\"imputer\", eval(df_best_params[\"params.imputer\"].values[0])),\n                (\n                    \"discretizer\",\n                    eval(df_best_params[\"params.discretizer\"].values[0]),\n                ),\n                (\"scaler\", eval(df_best_params[\"params.scaler\"].values[0])),\n                (\"model\", model),\n            ]\n        )\n\n        pipe.fit(self.dados_X, self.dados_y)\n\n        # logar metricas de avalia\u00e7\u00e3o\n        y_val_preds = pipe.predict_log_proba(self.dados_X)[:, 1]\n        model_eval = ModelEvaluation(model, self.dados_X, self.dados_y)\n        val_roc_auc = model_eval.evaluate_predictions(\n            self.dados_y, y_val_preds\n        )\n        mlflow.log_metric(\"valid_roc_auc\", val_roc_auc)\n\n        # registrar o modelo\n        mlflow.sklearn.log_model(\n            pipe,\n            self.model_name,\n            pyfunc_predict_fn=\"predict_proba\",\n            input_example=self.dados_X.iloc[[0]],\n            registered_model_name=self.model_name,\n        )\n</code></pre>"},{"location":"train/#src.train.train.TrainModels.__init__","title":"<code>__init__(dados_X, dados_y)</code>","text":"<p>Inicializa uma inst\u00e2ncia da classe TrainModels.</p> <p>Parameters:</p> Name Type Description Default <code>dados_X</code> <code>DataFrame</code> <p>O DataFrame contendo os recursos de entrada.</p> required <code>dados_y</code> <code>DataFrame</code> <p>O DataFrame contendo os r\u00f3tulos alvo.</p> required Source code in <code>src/train/train.py</code> <pre><code>def __init__(self, dados_X: pd.DataFrame, dados_y: pd.DataFrame):\n    \"\"\"\n    Inicializa uma inst\u00e2ncia da classe TrainModels.\n\n    Args:\n        dados_X (pd.DataFrame): O DataFrame contendo os recursos de entrada.\n        dados_y (pd.DataFrame): O DataFrame contendo os r\u00f3tulos alvo.\n    \"\"\"\n\n    self.dados_X = dados_X\n    self.dados_y = dados_y\n    self.model_name = load_config_file().get(\"model_name\")\n</code></pre>"},{"location":"train/#src.train.train.TrainModels.get_best_model","title":"<code>get_best_model()</code>","text":"<p>Obt\u00e9m os melhores par\u00e2metros e a m\u00e9trica de desempenho do melhor modelo do MLflow.</p> <p>Returns:</p> Type Description <code>Tuple[float, DataFrame]</code> <p>Uma tupla contendo a melhor m\u00e9trica de desempenho e os melhores par\u00e2metros do modelo.</p> Source code in <code>src/train/train.py</code> <pre><code>def get_best_model(self) -&gt; Tuple[float, pd.DataFrame]:\n    \"\"\"\n    Obt\u00e9m os melhores par\u00e2metros e a m\u00e9trica de desempenho do melhor modelo do MLflow.\n\n    Returns:\n        Uma tupla contendo a melhor m\u00e9trica de desempenho e os melhores par\u00e2metros do modelo.\n    \"\"\"\n\n    logger.info(\"Obtendo o melhor modelo do MLFlow\")\n    df_mlflow = mlflow.search_runs(\n        filter_string=\"metrics.valid_roc_auc &lt; 1\"\n    ).sort_values(\"metrics.valid_roc_auc\", ascending=False)\n    run_id = df_mlflow.loc[df_mlflow[\"metrics.valid_roc_auc\"].idxmax()][\n        \"run_id\"\n    ]\n    df_best_params = df_mlflow.loc[df_mlflow[\"run_id\"] == run_id][\n        [\n            \"params.class_weight\",\n            \"params.discretizer\",\n            \"params.warm_start\",\n            \"params.imputer\",\n            \"params.solver\",\n            \"params.scaler\",\n            \"params.max_iter\",\n            \"params.fit_intercept\",\n            \"params.tol\",\n            \"params.multi_class\",\n            \"params.C\",\n        ]\n    ]\n    best_roc_auc = df_mlflow.loc[\n        df_mlflow[\"metrics.valid_roc_auc\"].idxmax()\n    ][\"metrics.valid_roc_auc\"]\n\n    return best_roc_auc, df_best_params\n</code></pre>"},{"location":"train/#src.train.train.TrainModels.run","title":"<code>run()</code>","text":"<p>Executa o treinamento do modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros obtidos durante a busca do MLflow.</p> Source code in <code>src/train/train.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"\n    Executa o treinamento do modelo de Regress\u00e3o Log\u00edstica com os melhores par\u00e2metros\n    obtidos durante a busca do MLflow.\n    \"\"\"\n\n    _, df_best_params = self.get_best_model()\n    logger.info(f\"Iniciando o treinamento do modelo: {self.model_name}\")\n\n    with mlflow.start_run(run_name=\"final_model\"):\n        mlflow.set_tag(\"model_name\", self.model_name)\n\n        model = LogisticRegression(\n            warm_start=eval(df_best_params[\"params.warm_start\"].values[0]),\n            multi_class=df_best_params[\"params.multi_class\"].values[0],\n            class_weight=df_best_params[\"params.class_weight\"].values[0],\n            max_iter=int(df_best_params[\"params.max_iter\"].values[0]),\n            C=float(df_best_params[\"params.C\"].values[0]),\n            solver=df_best_params[\"params.solver\"].values[0],\n            tol=float(df_best_params[\"params.tol\"].values[0]),\n        )\n\n    pipe = Pipeline(\n        [\n            (\"imputer\", eval(df_best_params[\"params.imputer\"].values[0])),\n            (\n                \"discretizer\",\n                eval(df_best_params[\"params.discretizer\"].values[0]),\n            ),\n            (\"scaler\", eval(df_best_params[\"params.scaler\"].values[0])),\n            (\"model\", model),\n        ]\n    )\n\n    pipe.fit(self.dados_X, self.dados_y)\n\n    # logar metricas de avalia\u00e7\u00e3o\n    y_val_preds = pipe.predict_log_proba(self.dados_X)[:, 1]\n    model_eval = ModelEvaluation(model, self.dados_X, self.dados_y)\n    val_roc_auc = model_eval.evaluate_predictions(\n        self.dados_y, y_val_preds\n    )\n    mlflow.log_metric(\"valid_roc_auc\", val_roc_auc)\n\n    # registrar o modelo\n    mlflow.sklearn.log_model(\n        pipe,\n        self.model_name,\n        pyfunc_predict_fn=\"predict_proba\",\n        input_example=self.dados_X.iloc[[0]],\n        registered_model_name=self.model_name,\n    )\n</code></pre>"},{"location":"utils/","title":"Utils","text":"Utils"},{"location":"utils/#src.utils.utils.load_config_file","title":"<code>load_config_file()</code>","text":"<p>Carrega um arquivo de configura\u00e7\u00e3o YAML a partir de um caminho relativo definido.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict</code> <p>Um objeto Python contendo as configura\u00e7\u00f5es carregadas do arquivo YAML.</p> Source code in <code>src/utils/utils.py</code> <pre><code>def load_config_file() -&gt; Dict:\n    \"\"\"\n    Carrega um arquivo de configura\u00e7\u00e3o YAML a partir de um caminho relativo definido.\n\n    Returns:\n        dict: Um objeto Python contendo as configura\u00e7\u00f5es carregadas do arquivo YAML.\n\n    \"\"\"\n\n    diretoria_atual = os.path.dirname(os.path.abspath(__file__))\n\n    caminho_relativo = os.path.join(\"..\", \"..\", \"config\", \"config.yaml\")\n\n    config_file_path = os.path.abspath(\n        os.path.join(diretoria_atual, caminho_relativo)\n    )\n\n    config_file = yaml.safe_load(open(config_file_path, \"rb\"))\n\n    return config_file\n</code></pre>"},{"location":"utils/#src.utils.utils.save_model","title":"<code>save_model(model)</code>","text":"<p>Salva o modelo treinado no disco.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>O modelo treinado a ser salvo no disco.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/utils/utils.py</code> <pre><code>def save_model(model: Any) -&gt; None:\n    \"\"\"\n    Salva o modelo treinado no disco.\n\n    Args:\n        model: O modelo treinado a ser salvo no disco.\n\n    Returns:\n        None\n    \"\"\"\n\n    diretoria_atual = os.path.dirname(os.path.abspath(__file__))\n\n    caminho_relativo = os.path.join(\n        \"..\", \"..\", \"models\", load_config_file().get(\"model_name\")\n    )\n\n    model_path = os.path.join(diretoria_atual, caminho_relativo)\n\n    joblib.dump(model, model_path)\n</code></pre>"}]}